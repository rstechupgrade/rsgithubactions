
name: Databricks Workflow

on:
  push:
    branches:
      - main

jobs:
  list-files-on-databricks:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v2


    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
        
    - name: Set up Azure CLI
      run: |
        curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

    - name: Log in with Azure
      uses: azure/login@v1
      with:
        creds: '${{ secrets.AZURE_CREDENTIALS_2 }}'
        
    - name: Generate Access Token
      id: access_token
      run: |
        access_token=$(az account get-access-token --resource=${{ secrets.SPN_RESOURCE }} --query 'accessToken' -o tsv)

    - name: Log out from Azure
      run: az logout
        
    - name: Install Databricks CLI
      run: |
        pip install databricks-cli
        
    - name: List files in cwd
      run: |
        echo 'before'
        ls
        cat > ./test1.py << EOF
        This is a test file
        EOF
        echo "[DBX]                                                               
        host = ${{ secrets.DBX_H }}
        token = ${{ steps.access_token.outputs.access_token }}" > ./databricks.cfg
        echo 'after..'
        pwd
        ls -ltrh
        cat ./databricks.cfg
        
    - name: List Files on DBFS
      env:
          DATABRICKS_HOST: ${{ secrets.DBX_H }}
          DATABRICKS_TOKEN: ${{ steps.access_token.outputs.access_token }}
      run: |
        echo ${{ steps.access_token.outputs.access_token }} > token-file
        databricks configure --token --profile DBX
        rm -f token-file
        echo 'configured!'
        databricks fs ls dbfs:/tmp/
        databricks fs cp --recursive ./test1.py dbfs:/tmp/
        
        
          
        
        
    
